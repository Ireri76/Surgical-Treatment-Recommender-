{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ecea40-f6b2-41d7-8697-d8542b6ef19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and Preprocess the Data\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "# Load data\n",
    "file_path = 'PreComplication_Data_Imputed.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Select relevant columns\n",
    "state_columns = ['Gender', 'Age', 'BMI', 'WBCs', 'Na', 'Hb', 'K']\n",
    "action_column = 'SurgicalProcedure'\n",
    "reward_column = 'ComplicatedAppendicitis'\n",
    "\n",
    "# Discretize continuous features for manageable state space\n",
    "continuous_columns = ['Age', 'BMI', 'WBCs', 'Na', 'Hb', 'K']\n",
    "binner = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='quantile')\n",
    "df[continuous_columns] = binner.fit_transform(df[continuous_columns])\n",
    "\n",
    "# Ensure all state columns are integer (discrete)\n",
    "df[state_columns] = df[state_columns].astype(int)\n",
    "\n",
    "# Preview the processed data\n",
    "print(\"Processed data sample:\")\n",
    "print(df[state_columns + [action_column, reward_column]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9926d72e-fbe1-4590-94a8-848e4f41d0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define State-Action Space and Initialize Q-Table\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Define state and action components\n",
    "state_features = ['Gender', 'Age', 'BMI', 'WBCs', 'Na', 'Hb', 'K']\n",
    "actions = [0, 1]  # 0 = Open surgery, 1 = Laparoscopy\n",
    "\n",
    "# Get the number of unique values in each discretized feature\n",
    "gender_bins = df['Gender'].nunique()\n",
    "age_bins = df['Age'].nunique()\n",
    "bmi_bins = df['BMI'].nunique()\n",
    "wbc_bins = df['WBCs'].nunique()\n",
    "na_bins = df['Na'].nunique()\n",
    "hb_bins = df['Hb'].nunique()\n",
    "k_bins = df['K'].nunique()\n",
    "\n",
    "# Define the shape of the Q-table\n",
    "q_table_shape = (gender_bins, age_bins, bmi_bins, wbc_bins, na_bins, hb_bins, k_bins, len(actions))\n",
    "\n",
    "# Initialize Q-table with zeros\n",
    "q_table = np.zeros(q_table_shape)\n",
    "\n",
    "print(\"Q-table shape:\", q_table.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe63bb22-ae67-45e6-b9a5-96ab9b607812",
   "metadata": {},
   "source": [
    "NB\n",
    "The shape confirms everything is structured correctly for reinforcement learning:\n",
    "1. 2 options for Gender\n",
    "2. 3 bins each for Age, BMI, WBCs, Na, Hb, and K\n",
    "3. 2 actions: Open surgery and Laparoscopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dee0d8-55d1-46f8-aef6-cadd05957e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Hyperparameters\n",
    "alpha = 0.1      # Learning rate\n",
    "gamma = 0.9      # Discount factor\n",
    "episodes = 1000  # Number of training iterations\n",
    "\n",
    "# Re-initialize the Q-table (if necessary)\n",
    "q_table = np.zeros((2, 3, 3, 3, 3, 3, 3, 2))  # Shape confirmed earlier\n",
    "\n",
    "# Start training\n",
    "for episode in range(episodes):\n",
    "    # Shuffle data each episode for randomness\n",
    "    data_shuffled = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    for idx, row in data_shuffled.iterrows():\n",
    "        # Get the current state and action\n",
    "        state = row[state_columns].tolist()\n",
    "        action = row[action_column]\n",
    "        reward = -1 if row[reward_column] == 1 else 1  # -1 for complication, +1 for no complication\n",
    "\n",
    "        # In this simplified setup, we assume next_state = current state\n",
    "        next_state = state\n",
    "\n",
    "        # Q-learning update\n",
    "        current_q = q_table[tuple(state + [action])]\n",
    "        max_future_q = np.max(q_table[tuple(next_state)])\n",
    "        new_q = (1 - alpha) * current_q + alpha * (reward + gamma * max_future_q)\n",
    "        q_table[tuple(state + [action])] = new_q\n",
    "\n",
    "        # üîç Step 4B: Add logging every 100 episodes\n",
    "        if episode % 100 == 0 and idx == 0:  # Only log once per episode\n",
    "            print(f\"Episode {episode} | Updated Q{tuple(state + [action])} = {new_q:.4f}\")\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce3411e-caf5-4306-8ed4-563b4aea325c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train the Q-learning agent\n",
    "# We‚Äôll loop through the dataset and update the Q-table using the standard Q-learning update rule:\n",
    "# Q(s, a) ‚Üê Q(s, a) + Œ± √ó [r + Œ≥ √ó max Q(s‚Ä≤, a‚Ä≤) ‚àí Q(s, a)]\n",
    "# Where:\n",
    "# s is the current state\n",
    "# a is the action taken\n",
    "# r is the reward\n",
    "# s' is the next state\n",
    "# Œ± is the learning rate\n",
    "# Œ≥ is the discount factor\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Hyperparameters\n",
    "alpha = 0.1   # Learning rate\n",
    "gamma = 0.95  # Discount factor\n",
    "epochs = 100  # Number of iterations over the dataset\n",
    "\n",
    "# Train Q-learning agent\n",
    "for epoch in range(epochs):\n",
    "    for index, row in df.iterrows():\n",
    "        # Extract current state and action\n",
    "        state = (\n",
    "            row['Gender'],\n",
    "            row['Age'],\n",
    "            row['BMI'],\n",
    "            row['WBCs'],\n",
    "            row['Na'],\n",
    "            row['Hb'],\n",
    "            row['K']\n",
    "        )\n",
    "        action = row[action_column]\n",
    "        reward = 1 - row[reward_column]  # Reward = 1 if NOT complicated appendicitis (we want to avoid complications)\n",
    "\n",
    "        # In this context, assume same state because we have no temporal transitions\n",
    "        next_state = state\n",
    "\n",
    "        # Q-learning update\n",
    "        current_q = q_table[state][action]\n",
    "        max_future_q = np.max(q_table[next_state])\n",
    "        new_q = current_q + alpha * (reward + gamma * max_future_q - current_q)\n",
    "        q_table[state][action] = new_q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04568b5f-6a17-4f27-b550-43c1d111bb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4A: Predict Best Treatment Using Q-table\n",
    "\n",
    "# Function to get best treatment from Q-table\n",
    "def predict_best_treatment(state_row, q_table):\n",
    "    gender, age, bmi, wbcs, na, hb, k = state_row\n",
    "    return np.argmax(q_table[gender, age, bmi, wbcs, na, hb, k])\n",
    "\n",
    "# Apply to the whole dataset\n",
    "df['PredictedTreatment'] = df[state_columns].apply(lambda row: predict_best_treatment(row, q_table), axis=1)\n",
    "\n",
    "# Compare predicted vs actual\n",
    "comparison = df[['SurgicalProcedure', 'PredictedTreatment']]\n",
    "print(\"Comparison of actual vs predicted treatments:\")\n",
    "print(comparison.head(10))\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (df['SurgicalProcedure'] == df['PredictedTreatment']).mean()\n",
    "print(f\"\\nPrediction Accuracy: {accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb516e94-e84b-4fc7-abe4-218b81d1bfb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
